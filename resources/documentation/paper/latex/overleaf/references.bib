@techreport{chang2025,
  author       = {Chang, E. and others},
  title        = {{SagaLLM}: Context Management, Validation, and Transaction Guarantees for Multi-Agent {LLM} Planning},
  institution  = {Stanford University},
  year         = {2025}
}

@misc{breunig2025,
  author       = {Breunig, D.},
  title        = {How Long Contexts Fail},
  year         = {2025},
  howpublished = {dbreunig.com Blog},
  note         = {Accessed: 2025}
}

@misc{patel2025,
  author       = {Patel, M.},
  title        = {Why {LangChain} Fails in Production: 7 Hidden Problems},
  year         = {2025},
  howpublished = {LinkedIn post},
  note         = {Accessed: 2025}
}

@misc{ruan2024,
  author       = {Ruan, J.},
  title        = {Context Engineering in {LLM}-Based Agents},
  year         = {2024},
  howpublished = {Medium},
  note         = {Accessed: 2025}
}

@inproceedings{wu2025,
  author       = {Wu, Y. and others},
  title        = {{IsolateGPT}: An Execution Isolation Architecture for {LLM}-Based Agentic Systems},
  booktitle    = {NDSS Symposium 2025},
  year         = {2025}
}

@misc{wand2025,
  author       = {Wand AI Research and Fatemi, M.},
  title        = {Compounding Error Effect in Large Language Models: A Growing Challenge},
  year         = {2025},
  howpublished = {Wand AI Blog},
  note         = {Accessed: 2025}
}

@misc{ibm2025,
  author       = {Winland, V. and Noble, J.},
  title        = {What is {LLM} Orchestration?},
  year         = {2025},
  howpublished = {IBM Think Blog},
  note         = {Accessed: 2025}
}

@article{delorenzo2025,
  author       = {DeLorenzo, M. and others},
  title        = {Abstractions-of-Thought: Intermediate Representations for {LLM} Reasoning in Hardware Design},
  journal      = {arXiv preprint arXiv:2505.15873},
  year         = {2025}
}

@article{qiu2025,
  author       = {Qiu, L. and others},
  title        = {Blueprint First, Model Second: A Framework for Deterministic {LLM} Workflow},
  journal      = {arXiv preprint arXiv:2508.02721},
  year         = {2025}
}

@misc{sai2025,
  author       = {Sai, P.},
  title        = {Evaluating {AI} Transparency: What Do Users Really Need to Understand?},
  year         = {2025},
  howpublished = {AI/UI Medium Publication},
  note         = {Accessed: 2025}
}

@misc{saga2025,
  author       = {Modarressi, A. and Xiao, G. and others},
  title        = {{SagaLLM} Reference},
  year         = {2024},
  note         = {Cited in Chang (2025)}
}

@inproceedings{wang2024,
  author       = {Wang, P. and others},
  title        = {{AutoGen}: Enabling Next-Gen {LLM} Applications via Multi-Agent Conversation},
  booktitle    = {COLING 2024},
  year         = {2024}
}

@inproceedings{erol1994,
  author       = {Erol, K. and Hendler, J. and Nau, D. S.},
  title        = {{HTN} planning: Complexity and expressivity},
  booktitle    = {Proceedings of the 12th National Conference on Artificial Intelligence (AAAI-94)},
  pages        = {1123--1128},
  year         = {1994}
}

@article{yao2022,
  author       = {Yao, S. and Zhao, J. and Yu, D. and Narasimhan, K. and Zhao, D. and Cao, Y.},
  title        = {{ReAct}: Synergizing reasoning and acting in language models},
  journal      = {arXiv preprint arXiv:2210.03629},
  year         = {2022}
}

@article{shinn2023,
  author       = {Shinn, N. and Labash, A. and Liu, E. and Prystawski, B. and Park, C. H. and Raffel, C.},
  title        = {Reflexion: Language agents with verbal reinforcement learning},
  journal      = {arXiv preprint arXiv:2303.11366},
  year         = {2023}
}

@misc{ibm_langgraph,
  author       = {IBM},
  title        = {What is {LangGraph}?},
  year         = {2025},
  howpublished = {IBM Think},
  note         = {Retrieved December 2025}
}

@misc{wiki_ir,
  author       = {Wikipedia contributors},
  title        = {Intermediate representation},
  howpublished = {Wikipedia},
  note         = {Accessed: 2025}
}

@inproceedings{wei2022,
  author       = {Wei, J. and Wang, X. and Schuurmans, D. and Bosma, M. and Ichter, B. and Xia, F. and others and Le, Q.},
  title        = {Chain-of-thought prompting elicits reasoning in large language models},
  booktitle    = {ICLR 2023},
  year         = {2022}
}

@article{yao2023,
  author       = {Yao, S. and Zhao, J. and Yu, D. and Narasimhan, K. and Zhao, D. and Cao, Y.},
  title        = {Tree of Thoughts: Deliberate problem solving with large language models},
  journal      = {arXiv preprint arXiv:2305.10601},
  year         = {2023}
}

@article{han2023,
  author       = {Han, X. and Zhao, D.},
  title        = {Beyond chain-of-thought: Effective graph-of-thought reasoning in language models},
  journal      = {arXiv preprint arXiv:2305.16582},
  year         = {2023}
}

@incollection{silva_dl,
  author       = {Silva, A. R.},
  title        = {A sea of description languages},
  booktitle    = {Software Engineering Companion: Requirements Engineering},
  year         = {2025},
  note         = {Accessed: 2025}
}

@incollection{stanford_deontic,
  author       = {{Stanford Encyclopedia of Philosophy}},
  editor       = {Zalta, E. N.},
  title        = {Deontic Logic},
  booktitle    = {The Stanford Encyclopedia of Philosophy},
  edition      = {Fall 2021},
  year         = {2021}
}

@inproceedings{sordoni2025,
  author       = {Sordoni, A. and Proulx, J. and Gupta, M. and Maillard, J. and Pineau, J.},
  title        = {Are language models deontologically aligned?},
  booktitle    = {ACL 2025},
  year         = {2025}
}

