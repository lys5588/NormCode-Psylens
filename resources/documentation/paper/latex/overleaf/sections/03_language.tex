\section{The NormCode Language}

NormCode is designed around a single fundamental unit: the \textbf{inference}. An inference is not merely a function call; it is a structured assertion: ``Concept A is obtained by performing Operation B on Inputs C and D.'' This structure enforces the data isolation required for reliable AI planning.

\subsection{Core Syntax: The Inference Structure}

A NormCode plan is a hierarchy of inferences defined through three primary concept markers. The \texttt{<=} marker denotes a \textbf{Functional Concept}, which defines the operation (the ``verb'') and triggers an agent sequence. The functional concept's reference holds a \textbf{norm}---a paradigm or execution strategy that configures how the agent processes the operation. The \texttt{<-} marker denotes a \textbf{Value Concept}, which defines the data (the ``noun'') holding input or output state. The \texttt{<*} marker denotes a \textbf{Context Concept}, which provides in-loop state or carried data across iterations.

A typical inference in the \texttt{.ncds} (NormCode Draft Straightforward) format appears as:

\begin{verbatim}
<- summary
    <= summarize the text
    <- raw document
\end{verbatim}

This is read bottom-up: ``The \texttt{raw document} is used to \texttt{summarize the text}, producing the \texttt{summary}.'' The indentation defines the dependency: the parent (\texttt{summary}) cannot be resolved until its children are complete.

\subsection{The Multi-Format Ecosystem}

NormCode acknowledges that humans, compilers, and reviewers have different needs. The language exists in multiple isomorphic formats that serve distinct purposes throughout the development lifecycle.

The \textbf{.ncds (Draft Straightforward)} format serves as the human authoring format. It uses natural language with minimal structural markers and prioritizes speed and readability. Authors start here when creating new plans, focusing on rough logic and concept structure without worrying about formal syntax details.

The \textbf{.ncd (Draft)} format is the formal intermediate representation generated by the compiler. It resolves all ambiguities by assigning semantic types, fixing value orders with explicit bindings, and generating unique flow indices for every step. This machine-parsable format contains all technical details required for direct execution by the orchestrator.

The \textbf{.ncn (Natural)} format provides a compiler-generated narrative that translates the formal \texttt{.ncd} back into plain English. For example, an inference might render as ``(OUTPUT) The summary (ACTION) is obtained by summarizing the document (INPUT) using the raw document.'' This format allows non-technical domain experts to verify the plan's logic before execution without understanding the formal syntax.

The \textbf{.ncdn (Hybrid)} format combines both \texttt{.ncd} and \texttt{.ncn} views in a single editor interface. This enables developers to see the formal syntax alongside its natural language interpretation, facilitating review and modification.

Additionally, the \textbf{.nci.json} format provides a JSON representation of the inference structure, showing clear flow relationships between concepts. The final \textbf{.concept.json} and \textbf{.inference.json} formats constitute the executable repositories loaded by the orchestrator, containing separated concept definitions and inference working interpretations respectively.

The typical workflow proceeds from authoring in \texttt{.ncds}, through compiler-driven formalization to \texttt{.ncd} with its \texttt{.ncn} companion, then to structured \texttt{.nci.json}, and finally to the separated executable repositories. The compiler handles most transformations automatically, allowing users to focus on writing clear plans.

% [ILLUSTRATION OPPORTUNITY: Figure showing the format transformation pipeline from .ncds through all intermediate formats to executable repositories, with sample content at each stage]

\subsection{Semantic Concept Types}

NormCode types are semantic, not just structural. They tell the agent \textit{what} the data represents in the world, and each concept type is backed by a \textbf{Reference}---a multi-dimensional tensor that holds its content.

\textbf{Non-Functional Entities} represent the ``nouns'' and ``states'' of reasoning. \textbf{Objects} (\texttt{\{\}}) represent discrete items such as files, queries, or results. \textbf{Propositions} (\texttt{<>}) represent boolean states or facts that can be true or false, often extracted from declarative clauses or conditions. \textbf{Relations} (\texttt{[]}) represent collections or mappings, typically extracted from plurals or groupings. \textbf{Subjects} (\texttt{:S:}) represent active agents responsible for executing logic, holding a ``Body'' of tools and capabilities.

\textbf{Functional Operations} represent the ``verbs'' that transform data or evaluate states. Their references hold a \textbf{norm} that specifies the paradigm or execution strategy, bridging the Subject (agent with tools) and Object (data). \textbf{Imperatives} (\texttt{(\{\})} or \texttt{::()}) represent commands that change state or produce new data, invoking the Imperative Sequence. \textbf{Judgements} (\texttt{<\{\}>}) represent evaluations that return truth values, invoking the Judgement Sequence with an additional truth assertion step.

The critical distinction is that only functional concepts (imperatives and judgements) invoke LLM calls. Everything else is data structure manipulation.

\subsection{Syntactic Operators}

While semantic concepts invoke AI reasoning, syntactic operators manage the plan's data flow deterministically. These operators constitute a tensor algebra for AI planning, reshaping, combining, traversing, and gating references without examining actual content. This makes them free (no LLM calls), deterministic (same input produces same output), and auditable (exact structural changes are traceable).

The \textbf{Assigning} family (\texttt{\$}) controls which data flows forward. The identity operator (\texttt{\$=}) merges two concept names as aliases. The abstraction operator (\texttt{\$\%}) reifies a literal definition as data. The specification operator (\texttt{\$.}) selects the first valid result from candidates. The continuation operator (\texttt{\$+}) appends data along a specified axis. The selection operator (\texttt{\$-}) extracts elements by index, key, or unpacking.

The \textbf{Grouping} family (\texttt{\&}) controls how multiple references combine. The group-in operator (\texttt{\&[\{\}]}) bundles inputs into a labeled dictionary-like structure where items retain their names as keys. The group-across operator (\texttt{\&[\#]}) flattens inputs into a unified list where items lose their source identity.

The \textbf{Timing} family (\texttt{@}) controls execution flow. The conditional operator (\texttt{@:'}) executes only if a condition is true. The negated conditional (\texttt{@:!}) executes only if a condition is false. The sequencing operator (\texttt{@.}) ensures execution occurs after a dependency completes.

The \textbf{Looping} family (\texttt{*}) controls iteration. The iterate operator (\texttt{*.}) traverses a collection element-by-element while carrying state forward across iterations. Loop variables use version markers: \texttt{*1} for the current value in loop 1, \texttt{*-1} for the previous iteration's value, and \texttt{*0} for the initial value before any iteration.

All syntactic operators share a unified modifier system: \texttt{\%>} indicates source (input), \texttt{\%<} indicates target (output), \texttt{\%:} indicates axis (dimension), \texttt{\%\^{}} indicates carry (state), \texttt{\%@} indicates index (position), and \texttt{\%+} indicates creation of a new axis.

\subsection{Plan Addressability}

Every step in a NormCode plan is assigned a unique \textbf{Flow Index} (e.g., \texttt{1.2.3}) based on its position in the hierarchical structure. Each number represents a level in the tree, with deeper nesting producing longer indices. This indexing system enables precise debugging where errors can be localized to exact steps, targeted intervention where execution can be paused at specific points, auditing where inputs for any step can be inspected, and cross-referencing where steps can explicitly depend on others by index.

Flow indices are generated during the Formalization phase and persist through execution, providing stable addresses that survive plan modifications and enabling checkpoint-based resumption.

\subsection{Semi-Formality: Balancing Structure and Flexibility}

NormCode's ``semi-formal'' nature operates in two complementary ways that address the fundamental tension between expressiveness and precision.

First, NormCode supports \textbf{Conceptual Preservation through Progressive Formalization}. Natural language content is allowed within formal structure, enabling users to write \texttt{::(summarize the text)} without immediately defining implementation details. The structure formalizes \textit{how} concepts relate to others (dependencies and data flow) while leaving \textit{content} flexible until execution. Plans can start as rough sketches and be iteratively refined into rigorous logic, supporting exploration before commitment.

Second, NormCode enforces \textbf{Strictness Only Where Necessary}. Syntax is strict precisely to the extent required for compilation: establishing unique concept identities, resolving data flow dependencies, and extracting working interpretations that determine which agent sequence to invoke.

Beyond these requirements, semantic content can remain in natural language. This prevents the brittleness of traditional formal methods where a single syntax error invalidates an entire specification, while providing sufficient structure for reliable orchestration. The name ``NormCode'' references normative reasoning---rules and norms that agents must follow. Each step follows the norm of ``only see what you're explicitly given,'' and adherence to these norms is structurally verifiable.

