\begin{abstract}
Multi-step workflows that chain large language model (LLM) calls suffer from \textit{context pollution}: as information accumulates across steps, models hallucinate, confuse intermediate outputs, and lose track of task constraints. We present \textbf{NormCode}, a semi-formal language for constructing \textit{plans of inferences}---structured decompositions where each step operates in data isolation, receiving only explicitly passed inputs. This eliminates cross-step contamination by construction. NormCode enforces a strict separation between \textit{semantic operations} (LLM-driven reasoning, non-deterministic) and \textit{syntactic operations} (deterministic data restructuring), enabling precise cost and reliability tracing. The language exists in multiple isomorphic formats: \texttt{.ncds} for draft authoring, \texttt{.ncd} for formal machine execution, \texttt{.ncn} for natural language verification, and \texttt{.ncdn} for hybrid editing---supporting progressive formalization from sketch to production. A four-phase compilation pipeline (Derivation, Formalization, Post-Formalization, and Activation) transforms natural language intent into executable JSON repositories. The working implementation includes a visual Canvas App debugger built on React Flow and FastAPI, providing real-time graph visualization, breakpoint debugging, and multi-agent configuration. We validate NormCode through two demonstrations: (1) a base-X addition algorithm achieving 100\% accuracy on arbitrary-length inputs, and (2) self-hosted execution of NormCode's own compiler pipeline. The orchestrator provides dependency-driven scheduling, SQLite-backed checkpointing, and loop management with tensor-structured references. By making AI workflows auditable by construction, NormCode addresses a critical need for transparency in high-stakes domains such as legal reasoning, medical decision-making, and financial analysis.
\end{abstract}
